{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oay4hsK7dMhZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the entire model\n",
        "model = load_model(\"model.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "# Define image size (same as the target size used in the generator)\n",
        "image_size = (224, 224)\n",
        "\n",
        "def preprocess_user_image(image_path):\n",
        "    \"\"\"\n",
        "    Preprocesses a user-provided image for prediction.\n",
        "\n",
        "    Args:\n",
        "    - image_path (str): Path to the user's input image.\n",
        "\n",
        "    Returns:\n",
        "    - preprocessed_image (numpy.ndarray): Preprocessed image ready for model prediction.\n",
        "    \"\"\"\n",
        "    image_size = (224, 224)\n",
        "    # Step 1: Load the image and resize to target size\n",
        "    input_image = load_img(image_path, target_size=image_size)\n",
        "\n",
        "    # Step 2: Convert the image to a numpy array\n",
        "    input_array = img_to_array(input_image)\n",
        "\n",
        "    # Step 3: Normalize the image (rescale pixel values to range [0, 1])\n",
        "    input_array = input_array / 255.0\n",
        "\n",
        "    # Step 4: Add a batch dimension (to match model's expected input shape)\n",
        "    input_array = np.expand_dims(input_array, axis=0)  # Shape becomes (1, 224, 224, 3)\n",
        "\n",
        "    return input_array\n",
        "\n",
        "# Example usage\n",
        "image_path = 'malignant (1).png'  # Replace with the actual path to the user's image\n",
        "preprocessed_image = preprocess_user_image(image_path)\n",
        "\n",
        "# The preprocessed_image can now be passed to the model for prediction\n",
        "predictions = model.predict(preprocessed_image)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPqWoRGreuB5",
        "outputId": "2cb80eb2-7a6b-4214-abdd-14f6ee4eaeff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697ms/step\n",
            "Predictions: [[1.0927594e-02 9.8899698e-01 7.5433178e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlssYmgIet-R"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example 2D array\n",
        "predictions = np.array(predictions)\n",
        "\n",
        "# Convert to 1D array\n",
        "flattened_predictions = predictions.flatten()\n",
        "\n",
        "print(flattened_predictions)\n",
        "print(flattened_predictions.argmax())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiCemHflet7-",
        "outputId": "53cd4151-2718-4037-ec1c-e6d108cc1993"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0927594e-02 9.8899698e-01 7.5433178e-05]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5vck5Hddet5q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eIop-WKWet3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VO_ut3U5et05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y0zJfwrCetyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTu_GU20etwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3G-gzV7Tettv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R9GNwSjjetrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgJH-PBjeto3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tpWtYofQetmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQWhFHhzetj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phuRRxs7ethX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "II4Wcxpfete7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}